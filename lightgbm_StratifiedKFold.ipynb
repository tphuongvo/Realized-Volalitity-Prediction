{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "266s1jxZFnrk"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# reading file\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Modelling\n",
        "import os\n",
        "import random\n",
        "import pickle\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import lightgbm as lgb\n",
        "from typing import List, Tuple\n",
        "from collections import Counter, defaultdict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8qouoebff3t2"
      },
      "outputs": [],
      "source": [
        "root_path = \"data\"\n",
        "save_dir='checkpoints/artifacts/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St-nTEpA5trr"
      },
      "source": [
        "## 4.4 Lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8_ejh9ygmPvL"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(f'{root_path}/scaled_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV3PxQPfrEFP",
        "outputId": "1d7a58f7-0bf5-4825-e60b-b32efe1dbc67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 428932 entries, 0 to 428931\n",
            "Columns: 114 entries, row_id to stock_id\n",
            "dtypes: float64(112), int64(1), object(1)\n",
            "memory usage: 373.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "t0I4LqrXdJRL",
        "outputId": "67d15fa8-8aa2-4a25-96d1-a33db58db479"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>book.wap1.mean</th>\n",
              "      <th>book.wap1.std</th>\n",
              "      <th>book.wap1.sum</th>\n",
              "      <th>book.wap1.amin</th>\n",
              "      <th>book.wap1.amax</th>\n",
              "      <th>book.wap2.mean</th>\n",
              "      <th>book.wap2.std</th>\n",
              "      <th>book.wap2.sum</th>\n",
              "      <th>book.wap2.amin</th>\n",
              "      <th>...</th>\n",
              "      <th>trade.trade_volumn.amax</th>\n",
              "      <th>trade.weighted_price.realized_volatility</th>\n",
              "      <th>trade.weighted_price.mean</th>\n",
              "      <th>trade.weighted_price.std</th>\n",
              "      <th>trade.weighted_price.sum</th>\n",
              "      <th>trade.weighted_price.amin</th>\n",
              "      <th>trade.weighted_price.amax</th>\n",
              "      <th>target</th>\n",
              "      <th>stock_id</th>\n",
              "      <th>time_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0-5</td>\n",
              "      <td>0.533363</td>\n",
              "      <td>0.000693</td>\n",
              "      <td>0.457273</td>\n",
              "      <td>0.711488</td>\n",
              "      <td>0.318289</td>\n",
              "      <td>0.006905</td>\n",
              "      <td>0.003301</td>\n",
              "      <td>0.006713</td>\n",
              "      <td>0.059265</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000685</td>\n",
              "      <td>0.221584</td>\n",
              "      <td>0.505270</td>\n",
              "      <td>0.000578</td>\n",
              "      <td>0.063568</td>\n",
              "      <td>0.701747</td>\n",
              "      <td>0.334114</td>\n",
              "      <td>0.004136</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0-11</td>\n",
              "      <td>0.511839</td>\n",
              "      <td>0.000262</td>\n",
              "      <td>0.288406</td>\n",
              "      <td>0.701066</td>\n",
              "      <td>0.295490</td>\n",
              "      <td>0.003434</td>\n",
              "      <td>0.000518</td>\n",
              "      <td>0.002298</td>\n",
              "      <td>0.032674</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000383</td>\n",
              "      <td>0.185708</td>\n",
              "      <td>0.484476</td>\n",
              "      <td>0.000304</td>\n",
              "      <td>0.047108</td>\n",
              "      <td>0.685883</td>\n",
              "      <td>0.312804</td>\n",
              "      <td>0.001445</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0-16</td>\n",
              "      <td>0.507535</td>\n",
              "      <td>0.000864</td>\n",
              "      <td>0.268528</td>\n",
              "      <td>0.686183</td>\n",
              "      <td>0.295734</td>\n",
              "      <td>0.001506</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>0.001055</td>\n",
              "      <td>0.003873</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000534</td>\n",
              "      <td>0.165812</td>\n",
              "      <td>0.478549</td>\n",
              "      <td>0.000932</td>\n",
              "      <td>0.038952</td>\n",
              "      <td>0.671526</td>\n",
              "      <td>0.310739</td>\n",
              "      <td>0.002168</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0-31</td>\n",
              "      <td>0.503150</td>\n",
              "      <td>0.000757</td>\n",
              "      <td>0.157038</td>\n",
              "      <td>0.687526</td>\n",
              "      <td>0.293131</td>\n",
              "      <td>0.002702</td>\n",
              "      <td>0.000438</td>\n",
              "      <td>0.001059</td>\n",
              "      <td>0.094997</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000614</td>\n",
              "      <td>0.119330</td>\n",
              "      <td>0.477461</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>0.022733</td>\n",
              "      <td>0.675102</td>\n",
              "      <td>0.309503</td>\n",
              "      <td>0.002195</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0-62</td>\n",
              "      <td>0.508009</td>\n",
              "      <td>0.000258</td>\n",
              "      <td>0.248900</td>\n",
              "      <td>0.698248</td>\n",
              "      <td>0.291719</td>\n",
              "      <td>0.003609</td>\n",
              "      <td>0.001814</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>0.007725</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000466</td>\n",
              "      <td>0.153132</td>\n",
              "      <td>0.480999</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>0.034103</td>\n",
              "      <td>0.682849</td>\n",
              "      <td>0.308352</td>\n",
              "      <td>0.001747</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428927</th>\n",
              "      <td>99-32751</td>\n",
              "      <td>0.514338</td>\n",
              "      <td>0.000459</td>\n",
              "      <td>0.762298</td>\n",
              "      <td>0.700714</td>\n",
              "      <td>0.298106</td>\n",
              "      <td>0.002725</td>\n",
              "      <td>0.000180</td>\n",
              "      <td>0.004761</td>\n",
              "      <td>0.203034</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004004</td>\n",
              "      <td>0.378631</td>\n",
              "      <td>0.487010</td>\n",
              "      <td>0.000431</td>\n",
              "      <td>0.165666</td>\n",
              "      <td>0.685309</td>\n",
              "      <td>0.314554</td>\n",
              "      <td>0.001279</td>\n",
              "      <td>99</td>\n",
              "      <td>32751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428928</th>\n",
              "      <td>99-32753</td>\n",
              "      <td>0.513508</td>\n",
              "      <td>0.000641</td>\n",
              "      <td>0.567139</td>\n",
              "      <td>0.699965</td>\n",
              "      <td>0.302769</td>\n",
              "      <td>0.002386</td>\n",
              "      <td>0.000286</td>\n",
              "      <td>0.003191</td>\n",
              "      <td>0.075675</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005794</td>\n",
              "      <td>0.355655</td>\n",
              "      <td>0.487363</td>\n",
              "      <td>0.000664</td>\n",
              "      <td>0.147813</td>\n",
              "      <td>0.685130</td>\n",
              "      <td>0.320784</td>\n",
              "      <td>0.000890</td>\n",
              "      <td>99</td>\n",
              "      <td>32753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428929</th>\n",
              "      <td>99-32758</td>\n",
              "      <td>0.500177</td>\n",
              "      <td>0.000643</td>\n",
              "      <td>0.781722</td>\n",
              "      <td>0.687706</td>\n",
              "      <td>0.290493</td>\n",
              "      <td>0.003294</td>\n",
              "      <td>0.000310</td>\n",
              "      <td>0.005757</td>\n",
              "      <td>0.065839</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012904</td>\n",
              "      <td>0.337123</td>\n",
              "      <td>0.472882</td>\n",
              "      <td>0.000552</td>\n",
              "      <td>0.134488</td>\n",
              "      <td>0.673030</td>\n",
              "      <td>0.307772</td>\n",
              "      <td>0.001782</td>\n",
              "      <td>99</td>\n",
              "      <td>32758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428930</th>\n",
              "      <td>99-32763</td>\n",
              "      <td>0.503555</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>0.788718</td>\n",
              "      <td>0.691726</td>\n",
              "      <td>0.290497</td>\n",
              "      <td>0.003460</td>\n",
              "      <td>0.000718</td>\n",
              "      <td>0.006058</td>\n",
              "      <td>0.008582</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003992</td>\n",
              "      <td>0.490609</td>\n",
              "      <td>0.476782</td>\n",
              "      <td>0.000309</td>\n",
              "      <td>0.267498</td>\n",
              "      <td>0.676454</td>\n",
              "      <td>0.307878</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>99</td>\n",
              "      <td>32763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428931</th>\n",
              "      <td>99-32767</td>\n",
              "      <td>0.507716</td>\n",
              "      <td>0.000212</td>\n",
              "      <td>0.651723</td>\n",
              "      <td>0.697314</td>\n",
              "      <td>0.291101</td>\n",
              "      <td>0.002872</td>\n",
              "      <td>0.000235</td>\n",
              "      <td>0.004279</td>\n",
              "      <td>0.109667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001241</td>\n",
              "      <td>0.346502</td>\n",
              "      <td>0.480488</td>\n",
              "      <td>0.000218</td>\n",
              "      <td>0.141151</td>\n",
              "      <td>0.682170</td>\n",
              "      <td>0.307848</td>\n",
              "      <td>0.001264</td>\n",
              "      <td>99</td>\n",
              "      <td>32767</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>428932 rows × 115 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          row_id  book.wap1.mean  book.wap1.std  book.wap1.sum  \\\n",
              "0            0-5        0.533363       0.000693       0.457273   \n",
              "1           0-11        0.511839       0.000262       0.288406   \n",
              "2           0-16        0.507535       0.000864       0.268528   \n",
              "3           0-31        0.503150       0.000757       0.157038   \n",
              "4           0-62        0.508009       0.000258       0.248900   \n",
              "...          ...             ...            ...            ...   \n",
              "428927  99-32751        0.514338       0.000459       0.762298   \n",
              "428928  99-32753        0.513508       0.000641       0.567139   \n",
              "428929  99-32758        0.500177       0.000643       0.781722   \n",
              "428930  99-32763        0.503555       0.000303       0.788718   \n",
              "428931  99-32767        0.507716       0.000212       0.651723   \n",
              "\n",
              "        book.wap1.amin  book.wap1.amax  book.wap2.mean  book.wap2.std  \\\n",
              "0             0.711488        0.318289        0.006905       0.003301   \n",
              "1             0.701066        0.295490        0.003434       0.000518   \n",
              "2             0.686183        0.295734        0.001506       0.000182   \n",
              "3             0.687526        0.293131        0.002702       0.000438   \n",
              "4             0.698248        0.291719        0.003609       0.001814   \n",
              "...                ...             ...             ...            ...   \n",
              "428927        0.700714        0.298106        0.002725       0.000180   \n",
              "428928        0.699965        0.302769        0.002386       0.000286   \n",
              "428929        0.687706        0.290493        0.003294       0.000310   \n",
              "428930        0.691726        0.290497        0.003460       0.000718   \n",
              "428931        0.697314        0.291101        0.002872       0.000235   \n",
              "\n",
              "        book.wap2.sum  book.wap2.amin  ...  trade.trade_volumn.amax  \\\n",
              "0            0.006713        0.059265  ...                 0.000685   \n",
              "1            0.002298        0.032674  ...                 0.000383   \n",
              "2            0.001055        0.003873  ...                 0.000534   \n",
              "3            0.001059        0.094997  ...                 0.000614   \n",
              "4            0.002100        0.007725  ...                 0.000466   \n",
              "...               ...             ...  ...                      ...   \n",
              "428927       0.004761        0.203034  ...                 0.004004   \n",
              "428928       0.003191        0.075675  ...                 0.005794   \n",
              "428929       0.005757        0.065839  ...                 0.012904   \n",
              "428930       0.006058        0.008582  ...                 0.003992   \n",
              "428931       0.004279        0.109667  ...                 0.001241   \n",
              "\n",
              "        trade.weighted_price.realized_volatility  trade.weighted_price.mean  \\\n",
              "0                                       0.221584                   0.505270   \n",
              "1                                       0.185708                   0.484476   \n",
              "2                                       0.165812                   0.478549   \n",
              "3                                       0.119330                   0.477461   \n",
              "4                                       0.153132                   0.480999   \n",
              "...                                          ...                        ...   \n",
              "428927                                  0.378631                   0.487010   \n",
              "428928                                  0.355655                   0.487363   \n",
              "428929                                  0.337123                   0.472882   \n",
              "428930                                  0.490609                   0.476782   \n",
              "428931                                  0.346502                   0.480488   \n",
              "\n",
              "        trade.weighted_price.std  trade.weighted_price.sum  \\\n",
              "0                       0.000578                  0.063568   \n",
              "1                       0.000304                  0.047108   \n",
              "2                       0.000932                  0.038952   \n",
              "3                       0.000729                  0.022733   \n",
              "4                       0.000182                  0.034103   \n",
              "...                          ...                       ...   \n",
              "428927                  0.000431                  0.165666   \n",
              "428928                  0.000664                  0.147813   \n",
              "428929                  0.000552                  0.134488   \n",
              "428930                  0.000309                  0.267498   \n",
              "428931                  0.000218                  0.141151   \n",
              "\n",
              "        trade.weighted_price.amin  trade.weighted_price.amax    target  \\\n",
              "0                        0.701747                   0.334114  0.004136   \n",
              "1                        0.685883                   0.312804  0.001445   \n",
              "2                        0.671526                   0.310739  0.002168   \n",
              "3                        0.675102                   0.309503  0.002195   \n",
              "4                        0.682849                   0.308352  0.001747   \n",
              "...                           ...                        ...       ...   \n",
              "428927                   0.685309                   0.314554  0.001279   \n",
              "428928                   0.685130                   0.320784  0.000890   \n",
              "428929                   0.673030                   0.307772  0.001782   \n",
              "428930                   0.676454                   0.307878  0.003100   \n",
              "428931                   0.682170                   0.307848  0.001264   \n",
              "\n",
              "        stock_id  time_id  \n",
              "0              0        5  \n",
              "1              0       11  \n",
              "2              0       16  \n",
              "3              0       31  \n",
              "4              0       62  \n",
              "...          ...      ...  \n",
              "428927        99    32751  \n",
              "428928        99    32753  \n",
              "428929        99    32758  \n",
              "428930        99    32763  \n",
              "428931        99    32767  \n",
              "\n",
              "[428932 rows x 115 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['time_id'] = df_train['row_id'].str.split('-', expand = True)[1]\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_X_y(data):\n",
        " Xfeature = data.drop(columns = [\"target\",\"row_id\"])\n",
        " y = data[\"target\"]\n",
        " return Xfeature, y\n",
        " \n",
        "\n",
        "def rmspe(y_true, y_pred):\n",
        "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
        "\n",
        "\n",
        "def feval_rmspe(y_pred, model, is_xgb=True):\n",
        "    y_true = model.get_label()\n",
        "\n",
        "    if is_xgb:\n",
        "        return \"RMSPE\", rmspe(y_true, y_pred)\n",
        "\n",
        "    return \"RMSPE\", rmspe(y_true, y_pred), False\n",
        "\n",
        "\n",
        "def feval_wrapper(y_pred, model):\n",
        "    return feval_rmspe(y_pred, model, is_xgb=False)\n",
        "\n",
        "\n",
        "def stratified_group_k_fold(X, y, groups, k, seed=None):\n",
        "    \"\"\" https://www.kaggle.com/jakubwasikowski/stratified-group-k-fold-cross-validation \"\"\"\n",
        "    labels_num = np.max(y) + 1\n",
        "    y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
        "    y_distr = Counter()\n",
        "    for label, g in zip(y, groups):\n",
        "        y_counts_per_group[g][label] += 1\n",
        "        y_distr[label] += 1\n",
        "\n",
        "    y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
        "    groups_per_fold = defaultdict(set)\n",
        "\n",
        "    def eval_y_counts_per_fold(y_counts, fold):\n",
        "        y_counts_per_fold[fold] += y_counts\n",
        "        std_per_label = []\n",
        "        for label in range(labels_num):\n",
        "            label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n",
        "            std_per_label.append(label_std)\n",
        "        y_counts_per_fold[fold] -= y_counts\n",
        "        return np.mean(std_per_label)\n",
        "    \n",
        "    groups_and_y_counts = list(y_counts_per_group.items())\n",
        "    random.Random(seed).shuffle(groups_and_y_counts)\n",
        "\n",
        "    for g, y_counts in tqdm(sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])), total=len(groups_and_y_counts)):\n",
        "        best_fold = None\n",
        "        min_eval = None\n",
        "        for i in range(k):\n",
        "            fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
        "            if min_eval is None or fold_eval < min_eval:\n",
        "                min_eval = fold_eval\n",
        "                best_fold = i\n",
        "        y_counts_per_fold[best_fold] += y_counts\n",
        "        groups_per_fold[best_fold].add(g)\n",
        "\n",
        "    all_groups = set(groups)\n",
        "    for i in range(k):\n",
        "        train_groups = all_groups - groups_per_fold[i]\n",
        "        test_groups = groups_per_fold[i]\n",
        "\n",
        "        train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
        "        test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
        "\n",
        "        yield train_indices, test_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # # full data\n",
        "X, y = get_X_y(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "X.reset_index(drop=True, inplace=True); y.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [col for col in df_train.columns if col not in {\"time_id\", \"target\", \"row_id\"}]\n",
        "feats_nostock = [col for col in df_train.columns if col not in {\"time_id\", \"target\", \"row_id\", \"stock_id\"}] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3830/3830 [03:13<00:00, 19.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 0: 343146 train, 85786 valid\n",
            "Fold 1: 343145 train, 85787 valid\n",
            "Fold 2: 343146 train, 85786 valid\n",
            "Fold 3: 343146 train, 85786 valid\n",
            "Fold 4: 343145 train, 85787 valid\n"
          ]
        }
      ],
      "source": [
        "# Create out of folds array\n",
        "y = df_train['target']\n",
        "# Iterate through each fold\n",
        "try_seed = 42\n",
        "KFOLD = 5\n",
        "CV_SPLIT = 'default' \n",
        "\n",
        "if CV_SPLIT == 'default':\n",
        "    #gkf = GroupKFold(n_splits=KFOLD)\n",
        "    skf = stratified_group_k_fold(X=df_train[feats_nostock], y=df_train['stock_id'].astype('category').cat.codes.values, \n",
        "                              groups=np.array(df_train['time_id'].astype('category').cat.codes.values), k=KFOLD, seed=try_seed)\n",
        "    folds = []\n",
        "\n",
        "    for i, (idx_train, idx_valid) in enumerate(skf):\n",
        "      # x_train, x_val = train.iloc[idx_train], train.iloc[idx_valid]\n",
        "      # y_train, y_val = y.iloc[idx_train], y.iloc[idx_valid]\n",
        "      folds.append((idx_train, idx_valid))\n",
        "      print(f'Fold {i}: {len(idx_train)} train, {len(idx_valid)} valid')\n",
        "else:\n",
        "    raise ValueError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "lgb_bl = {\n",
        "    \"boosting_type\": [\"gbdt\"],\n",
        "    \"max_depth\": [7],\n",
        "    \"num_leaves\": [128],\n",
        "    #\"early_stopping_rounds\":[10],\n",
        "\n",
        "    \"learning_rate\": [0.05],\n",
        "    \"subsample\": [0.72],\n",
        "    \"subsample_freq\": [4],\n",
        "    \"feature_fraction\": [0.4],\n",
        "    \"feature_fraction_bynode\": [0.8],\n",
        "    \"bagging_fraction\": [0.75],\n",
        "    \"bagging_freq\": [25],\n",
        "\n",
        "    \"min_data_in_leaf\": [1000],\n",
        "    \"min_sum_hessian_in_leaf\": [20],\n",
        "\n",
        "    \"lambda_l1\": [2],\n",
        "    \"lambda_l2\": [4],\n",
        "        \n",
        "    \"extra_trees\": [True],\n",
        "    \"force_col_wise\": [True],\n",
        "        \n",
        "    \"categorical_column\": [0],\n",
        "    \"n_jobs\": [-1],\n",
        "    \"verbose\": [-1],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_lgbm(X: pd.DataFrame, y: pd.DataFrame, folds: List[Tuple],output_dir,params):\n",
        "    global feval_wrapper\n",
        "\n",
        "    best_losses = []\n",
        "    best_predictions = []\n",
        "\n",
        "  # Iterate through each fold\n",
        "  \n",
        "    if CV_SPLIT == 'default':\n",
        "      #gkf = GroupKFold(n_splits=KFOLD)\n",
        "      skf = stratified_group_k_fold(X=X[feats_nostock], y=X['stock_id'].astype('category').cat.codes.values, \n",
        "                                groups=np.array(X['time_id'].astype('category').cat.codes.values), k=KFOLD, seed=try_seed)\n",
        "      # folds = []\n",
        "      \n",
        "      for cv_idx, (idx_train, idx_valid) in enumerate(skf):\n",
        "  # for cv_idx, (train_idx, valid_idx) in enumerate(folds):\n",
        "        X_tr, X_va = X.iloc[idx_train], X.iloc[idx_valid]\n",
        "        y_tr, y_va = y.iloc[idx_train], y.iloc[idx_valid]\n",
        "\n",
        "        X_tr = X_tr.drop(columns = ['time_id'], axis = 1)\n",
        "        X_va = X_va.drop(columns = ['time_id'], axis = 1)\n",
        "        \n",
        "        dtrain = lgb.Dataset(X_tr, y_tr, weight=1/np.square(y_tr))\n",
        "        dval = lgb.Dataset(X_va, y_va, weight=1/np.square(y_va))\n",
        "\n",
        "        print(f\"fold {cv_idx} train: {X_tr.shape}, valid: {X_va.shape}\")\n",
        "\n",
        "        model = lgb.train(params=params,\n",
        "                              num_boost_round=10000,\n",
        "                              train_set=dtrain,\n",
        "                              valid_sets=[dtrain, dval],\n",
        "                              verbose_eval=250,\n",
        "                              early_stopping_rounds=200,\n",
        "                              #early_stopping_rounds=1,\n",
        "                              feval=feval_wrapper)\n",
        "\n",
        "        fold_preds = model.predict(X_va)\n",
        "        valid_rmspe = rmspe(y_va, fold_preds)\n",
        "        #print(f\"\\nvalid rmspe of fold {fold}: {valid_rmspe}\")\n",
        "        \n",
        "        print(f\"\\nRMSPE of fold {cv_idx}: {valid_rmspe}\")\n",
        "        # import pdb; pdb.set_trace()\n",
        "        pickle.dump(model, open(os.path.join(output_dir, f\"lgb_bl_{cv_idx}.pkl\"), \"wb\"))\n",
        "        \n",
        "        \n",
        "        # import pdb; pdb.set_trace()\n",
        "        best_predictions.append(fold_preds)\n",
        "        best_losses.append(valid_rmspe)\n",
        "\n",
        "      return best_losses, best_predictions          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOt6V7Prp6ey",
        "outputId": "fa7abb98-e4a0-44e9-d91d-c4dd755cb973"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3830/3830 [02:56<00:00, 21.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 0 train: (343146, 112), valid: (85786, 112)\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.72 will be ignored. Current value: bagging_fraction=0.75\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=4 will be ignored. Current value: bagging_freq=25\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[250]\ttraining's RMSPE: 0.235759\tvalid_1's RMSPE: 0.250779\n",
            "[500]\ttraining's RMSPE: 0.230668\tvalid_1's RMSPE: 0.247403\n",
            "[750]\ttraining's RMSPE: 0.22782\tvalid_1's RMSPE: 0.245468\n",
            "[1000]\ttraining's RMSPE: 0.225753\tvalid_1's RMSPE: 0.244788\n",
            "[1250]\ttraining's RMSPE: 0.224071\tvalid_1's RMSPE: 0.244188\n",
            "[1500]\ttraining's RMSPE: 0.222679\tvalid_1's RMSPE: 0.244001\n",
            "[1750]\ttraining's RMSPE: 0.221361\tvalid_1's RMSPE: 0.244231\n",
            "Early stopping, best iteration is:\n",
            "[1650]\ttraining's RMSPE: 0.221876\tvalid_1's RMSPE: 0.243692\n",
            "\n",
            "RMSPE of fold 0: 0.2436921386092969\n",
            "fold 1 train: (343145, 112), valid: (85787, 112)\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.72 will be ignored. Current value: bagging_fraction=0.75\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=4 will be ignored. Current value: bagging_freq=25\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[250]\ttraining's RMSPE: 0.236959\tvalid_1's RMSPE: 0.238966\n",
            "[500]\ttraining's RMSPE: 0.231803\tvalid_1's RMSPE: 0.235901\n",
            "[750]\ttraining's RMSPE: 0.228933\tvalid_1's RMSPE: 0.234656\n",
            "[1000]\ttraining's RMSPE: 0.226827\tvalid_1's RMSPE: 0.23406\n",
            "[1250]\ttraining's RMSPE: 0.225169\tvalid_1's RMSPE: 0.233635\n",
            "[1500]\ttraining's RMSPE: 0.223675\tvalid_1's RMSPE: 0.233433\n",
            "Early stopping, best iteration is:\n",
            "[1450]\ttraining's RMSPE: 0.223966\tvalid_1's RMSPE: 0.233348\n",
            "\n",
            "RMSPE of fold 1: 0.23334786042129643\n",
            "fold 2 train: (343146, 112), valid: (85786, 112)\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.72 will be ignored. Current value: bagging_fraction=0.75\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=4 will be ignored. Current value: bagging_freq=25\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[250]\ttraining's RMSPE: 0.236739\tvalid_1's RMSPE: 0.241268\n",
            "[500]\ttraining's RMSPE: 0.231481\tvalid_1's RMSPE: 0.238033\n",
            "[750]\ttraining's RMSPE: 0.228556\tvalid_1's RMSPE: 0.236764\n",
            "[1000]\ttraining's RMSPE: 0.226452\tvalid_1's RMSPE: 0.23624\n",
            "[1250]\ttraining's RMSPE: 0.224692\tvalid_1's RMSPE: 0.235886\n",
            "[1500]\ttraining's RMSPE: 0.22322\tvalid_1's RMSPE: 0.235671\n",
            "[1750]\ttraining's RMSPE: 0.221966\tvalid_1's RMSPE: 0.235542\n",
            "[2000]\ttraining's RMSPE: 0.220773\tvalid_1's RMSPE: 0.235453\n",
            "Early stopping, best iteration is:\n",
            "[1864]\ttraining's RMSPE: 0.221377\tvalid_1's RMSPE: 0.235409\n",
            "\n",
            "RMSPE of fold 2: 0.23540885444959753\n",
            "fold 3 train: (343146, 112), valid: (85786, 112)\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.72 will be ignored. Current value: bagging_fraction=0.75\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=4 will be ignored. Current value: bagging_freq=25\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[250]\ttraining's RMSPE: 0.237229\tvalid_1's RMSPE: 0.235412\n",
            "[500]\ttraining's RMSPE: 0.232412\tvalid_1's RMSPE: 0.232281\n",
            "[750]\ttraining's RMSPE: 0.229553\tvalid_1's RMSPE: 0.23081\n",
            "[1000]\ttraining's RMSPE: 0.227473\tvalid_1's RMSPE: 0.229903\n",
            "[1250]\ttraining's RMSPE: 0.225751\tvalid_1's RMSPE: 0.229343\n",
            "[1500]\ttraining's RMSPE: 0.224326\tvalid_1's RMSPE: 0.229012\n",
            "[1750]\ttraining's RMSPE: 0.223003\tvalid_1's RMSPE: 0.228767\n",
            "[2000]\ttraining's RMSPE: 0.221793\tvalid_1's RMSPE: 0.228576\n",
            "[2250]\ttraining's RMSPE: 0.220677\tvalid_1's RMSPE: 0.228452\n",
            "[2500]\ttraining's RMSPE: 0.219622\tvalid_1's RMSPE: 0.228356\n",
            "[2750]\ttraining's RMSPE: 0.218608\tvalid_1's RMSPE: 0.228277\n",
            "[3000]\ttraining's RMSPE: 0.217645\tvalid_1's RMSPE: 0.22816\n",
            "[3250]\ttraining's RMSPE: 0.216716\tvalid_1's RMSPE: 0.228161\n",
            "[3500]\ttraining's RMSPE: 0.215837\tvalid_1's RMSPE: 0.228122\n",
            "[3750]\ttraining's RMSPE: 0.214983\tvalid_1's RMSPE: 0.228084\n",
            "Early stopping, best iteration is:\n",
            "[3601]\ttraining's RMSPE: 0.21549\tvalid_1's RMSPE: 0.228079\n",
            "\n",
            "RMSPE of fold 3: 0.22807922969671898\n",
            "fold 4 train: (343145, 112), valid: (85787, 112)\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.72 will be ignored. Current value: bagging_fraction=0.75\n",
            "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=4 will be ignored. Current value: bagging_freq=25\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[250]\ttraining's RMSPE: 0.236434\tvalid_1's RMSPE: 0.239888\n",
            "[500]\ttraining's RMSPE: 0.23137\tvalid_1's RMSPE: 0.23642\n",
            "[750]\ttraining's RMSPE: 0.228577\tvalid_1's RMSPE: 0.235151\n",
            "[1000]\ttraining's RMSPE: 0.2265\tvalid_1's RMSPE: 0.234409\n",
            "[1250]\ttraining's RMSPE: 0.224819\tvalid_1's RMSPE: 0.233993\n",
            "[1500]\ttraining's RMSPE: 0.223357\tvalid_1's RMSPE: 0.233677\n",
            "[1750]\ttraining's RMSPE: 0.222065\tvalid_1's RMSPE: 0.233377\n",
            "[2000]\ttraining's RMSPE: 0.220886\tvalid_1's RMSPE: 0.233321\n",
            "[2250]\ttraining's RMSPE: 0.219745\tvalid_1's RMSPE: 0.232998\n",
            "Early stopping, best iteration is:\n",
            "[2248]\ttraining's RMSPE: 0.219752\tvalid_1's RMSPE: 0.232993\n",
            "\n",
            "RMSPE of fold 4: 0.23299337480024299\n"
          ]
        }
      ],
      "source": [
        "lgbm_losses, lgbm_preds = train_lgbm(X, y, \n",
        "                              folds, \n",
        "                              output_dir=save_dir,\n",
        "                              params= lgb_bl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.23470429159543058"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(lgbm_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3iPK2jvqRF7v"
      },
      "outputs": [],
      "source": [
        "# with open(os.path.join(save_dir, f\"lgb_bl_0.pkl\"), 'rb') as f:\n",
        "#    model_0 = pickle.load(f) \n",
        "# with open(os.path.join(save_dir, f\"lgb_bl_1.pkl\"), 'rb') as f:\n",
        "#    model_1 = pickle.load(f) \n",
        "# with open(os.path.join(save_dir, f\"lgb_bl_2.pkl\"), 'rb') as f:\n",
        "#    model_2 = pickle.load(f) "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "lightgbm  StratifiedKFold.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "93a52d2716d37cb936144ccca0f460bb19246a32b6727480f5deda6579d2e26e"
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 ('learning')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
